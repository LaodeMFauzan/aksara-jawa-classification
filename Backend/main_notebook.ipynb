{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "main_notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr_rDVJvLYcl",
        "colab_type": "text"
      },
      "source": [
        "## Bangkit Final Project: Aksara Jawa Classification with Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B8_rvywLPMy",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEMQiRFrEm4D",
        "colab_type": "code",
        "outputId": "d667a4df-c490-46a4-91ef-b96249c31590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "!pip install -q kaggle\n",
        "!pip install keras==2.3.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjdKqVMdEpmb",
        "colab_type": "code",
        "outputId": "36c33e5c-26b4-439f-835a-4d45b8caadcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras,os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Colab library to upload files to notebook\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqjlrfMqE00y",
        "colab_type": "code",
        "outputId": "17c7a1bb-51df-482e-abbe-e348fabe3742",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7ee5360c-42ab-41a1-8abd-04c49898f978\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7ee5360c-42ab-41a1-8abd-04c49898f978\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTwyLWClE6gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWlUb1amTgLh",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIK8FaA1FDXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Download dataset from upstream\n",
        "!kaggle datasets download -d phiard/aksara-jawa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL6ZdRNYFFAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Unzip dataset into a folder\n",
        "!unzip aksara-jawa.zip -d dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "8kuLCQ2RLvov",
        "colab_type": "code",
        "outputId": "48eda5c9-26cb-4474-ea57-c48b5826390e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Do the image augmentation and rescale image\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/dataset/newdatasetaug/newtraining\",\n",
        "    target_size=(224,224),\n",
        "    batch_size=20)\n",
        "\n",
        "validation_data = validation_datagen.flow_from_directory(\n",
        "    directory=\"/content/dataset/newdatasetaug/newtesting\",\n",
        "    target_size=(224,224),\n",
        "    batch_size=20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1441 images belonging to 20 classes.\n",
            "Found 839 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M9ncqABBfnl",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y_iaPmwGkhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgOn6QCJ2zLW",
        "colab_type": "code",
        "outputId": "abc43c78-e44f-4534-db68-8838a6b9f2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=20, activation=\"softmax\"))\n",
        "\n",
        "opt = Adam(lr=0.000001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"dummy_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit_generator(steps_per_epoch=50,generator=train_data, validation_data= validation_data, validation_steps=5,epochs=50,callbacks=[checkpoint,early])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 20)                81940     \n",
            "=================================================================\n",
            "Total params: 134,342,484\n",
            "Trainable params: 134,342,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 31s 625ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9951 - val_accuracy: 0.0500\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.05000, saving model to dummy_model.h5\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 28s 562ms/step - loss: 2.9958 - accuracy: 0.0520 - val_loss: 2.9961 - val_accuracy: 0.0800\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.05000 to 0.08000, saving model to dummy_model.h5\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 2.9958 - accuracy: 0.0450 - val_loss: 2.9953 - val_accuracy: 0.0500\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.08000\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 2.9956 - accuracy: 0.0571 - val_loss: 2.9963 - val_accuracy: 0.0700\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.08000\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 29s 590ms/step - loss: 2.9958 - accuracy: 0.0469 - val_loss: 2.9942 - val_accuracy: 0.0600\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.08000\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 30s 603ms/step - loss: 2.9956 - accuracy: 0.0450 - val_loss: 2.9962 - val_accuracy: 0.0400\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.08000\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 2.9954 - accuracy: 0.0601 - val_loss: 2.9955 - val_accuracy: 0.0900\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.08000 to 0.09000, saving model to dummy_model.h5\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 28s 560ms/step - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9954 - val_accuracy: 0.0600\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.09000\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 30s 604ms/step - loss: 2.9954 - accuracy: 0.0530 - val_loss: 2.9935 - val_accuracy: 0.0808\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.09000\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 2.9954 - accuracy: 0.0571 - val_loss: 2.9953 - val_accuracy: 0.0100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.09000\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 2.9950 - accuracy: 0.0642 - val_loss: 2.9956 - val_accuracy: 0.0700\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.09000\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 2.9954 - accuracy: 0.0420 - val_loss: 2.9955 - val_accuracy: 0.0200\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.09000\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 29s 583ms/step - loss: 2.9949 - accuracy: 0.0581 - val_loss: 2.9949 - val_accuracy: 0.0800\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.09000\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 2.9948 - accuracy: 0.0520 - val_loss: 2.9950 - val_accuracy: 0.0600\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.09000\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 30s 592ms/step - loss: 2.9937 - accuracy: 0.0642 - val_loss: 2.9904 - val_accuracy: 0.0600\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.09000\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 2.9934 - accuracy: 0.0479 - val_loss: 2.9937 - val_accuracy: 0.0300\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.09000\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 2.9911 - accuracy: 0.0591 - val_loss: 2.9908 - val_accuracy: 0.0505\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.09000\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 31s 611ms/step - loss: 2.9908 - accuracy: 0.0470 - val_loss: 2.9804 - val_accuracy: 0.0500\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.09000\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 2.9850 - accuracy: 0.0673 - val_loss: 2.9749 - val_accuracy: 0.0800\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.09000\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 29s 589ms/step - loss: 2.9779 - accuracy: 0.0673 - val_loss: 2.9657 - val_accuracy: 0.0900\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.09000\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 30s 602ms/step - loss: 2.9575 - accuracy: 0.1150 - val_loss: 2.9551 - val_accuracy: 0.1100\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.09000 to 0.11000, saving model to dummy_model.h5\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 28s 555ms/step - loss: 2.9139 - accuracy: 0.1164 - val_loss: 2.8057 - val_accuracy: 0.0900\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.11000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 2.8707 - accuracy: 0.1230 - val_loss: 2.7373 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.11000 to 0.34000, saving model to dummy_model.h5\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 29s 574ms/step - loss: 2.8054 - accuracy: 0.1580 - val_loss: 2.6833 - val_accuracy: 0.1700\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.34000\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 29s 571ms/step - loss: 2.7388 - accuracy: 0.1529 - val_loss: 2.5096 - val_accuracy: 0.1600\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.34000\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 30s 601ms/step - loss: 2.7180 - accuracy: 0.1529 - val_loss: 2.3523 - val_accuracy: 0.2626\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.34000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 2.6264 - accuracy: 0.1794 - val_loss: 2.4143 - val_accuracy: 0.3800\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.34000 to 0.38000, saving model to dummy_model.h5\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 2.6101 - accuracy: 0.1830 - val_loss: 2.3559 - val_accuracy: 0.2100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.38000\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 2.6006 - accuracy: 0.2018 - val_loss: 2.1130 - val_accuracy: 0.2400\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.38000\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 2.5146 - accuracy: 0.2253 - val_loss: 2.0004 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.38000\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 30s 598ms/step - loss: 2.4573 - accuracy: 0.2310 - val_loss: 1.9031 - val_accuracy: 0.4500\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.38000 to 0.45000, saving model to dummy_model.h5\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 28s 566ms/step - loss: 2.4810 - accuracy: 0.2110 - val_loss: 2.1098 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.45000\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 29s 583ms/step - loss: 2.3468 - accuracy: 0.2870 - val_loss: 2.2279 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.45000\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 29s 587ms/step - loss: 2.3884 - accuracy: 0.2304 - val_loss: 2.0016 - val_accuracy: 0.3232\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.45000\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 30s 594ms/step - loss: 2.3872 - accuracy: 0.2569 - val_loss: 2.1009 - val_accuracy: 0.3900\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.45000\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 29s 582ms/step - loss: 2.3499 - accuracy: 0.2722 - val_loss: 2.4046 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.45000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 30s 596ms/step - loss: 2.3369 - accuracy: 0.2730 - val_loss: 2.2418 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.45000\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 29s 585ms/step - loss: 2.2189 - accuracy: 0.3109 - val_loss: 1.9959 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.45000\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 29s 584ms/step - loss: 2.2247 - accuracy: 0.3191 - val_loss: 1.7813 - val_accuracy: 0.4700\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.45000 to 0.47000, saving model to dummy_model.h5\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 29s 571ms/step - loss: 2.2048 - accuracy: 0.3130 - val_loss: 1.9935 - val_accuracy: 0.4400\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.47000\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 2.1367 - accuracy: 0.3405 - val_loss: 1.9457 - val_accuracy: 0.3800\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.47000\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 29s 572ms/step - loss: 2.1533 - accuracy: 0.3200 - val_loss: 2.0475 - val_accuracy: 0.3131\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.47000\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 30s 593ms/step - loss: 2.1348 - accuracy: 0.3181 - val_loss: 1.5754 - val_accuracy: 0.5100\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.47000 to 0.51000, saving model to dummy_model.h5\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 28s 556ms/step - loss: 2.1230 - accuracy: 0.3476 - val_loss: 1.7356 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.51000\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 29s 588ms/step - loss: 2.0758 - accuracy: 0.3630 - val_loss: 2.0936 - val_accuracy: 0.4000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.51000\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 1.9811 - accuracy: 0.3558 - val_loss: 2.0598 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.51000\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 30s 590ms/step - loss: 2.0306 - accuracy: 0.3780 - val_loss: 2.1985 - val_accuracy: 0.3900\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.51000\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 29s 578ms/step - loss: 1.9799 - accuracy: 0.3976 - val_loss: 1.3616 - val_accuracy: 0.6100\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.51000 to 0.61000, saving model to dummy_model.h5\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 29s 571ms/step - loss: 1.9851 - accuracy: 0.3880 - val_loss: 1.5547 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.61000\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 28s 557ms/step - loss: 1.9876 - accuracy: 0.3690 - val_loss: 2.0609 - val_accuracy: 0.4100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.61000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-YiFTNA3GKN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsfx_WIY0AU9",
        "colab_type": "code",
        "outputId": "33e18e09-f5e1-4829-c8d7-353765ad3231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ13HwYbDpGv",
        "colab_type": "text"
      },
      "source": [
        "## Save model to json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbcakyzxE9KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-yhByUkDq9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_dummy.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}